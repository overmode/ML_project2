{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Note book for the project 2 \n",
    "\n",
    "Kaggle competition link: [Submition]('https://www.kaggle.com/c/epfml17-text/submit')\n",
    "\n",
    "## Pipeline: \n",
    "\n",
    "\n",
    "### Create cooc matrix\n",
    "\n",
    "1. sh build_vocab.sh\n",
    "2. sh cut_vocab.sh\n",
    "3. python3 pickle_vocab.py\n",
    "4. python3 cooc.py\n",
    "\n",
    "Now given the co-occurrence matrix and the vocabulary, it is not hard to train GloVe word embeddings, that is to compute an embedding vector for wach word in the vocabulary. We suggest to implement SGD updates to train the matrix factorization, as in\n",
    "\n",
    "5. python3 glove_template.py\n",
    "\n",
    "Once you tested your system on the small set of 10% of all tweets, we suggest you run on the full datasets pos_train_full.txt, neg_train_full.txt\n",
    "\n",
    "### Building a Text Classifier:\n",
    "\n",
    "1. Construct Features for the Training Texts: Load the training tweets and the built GloVe word embeddings. Using the word embeddings, construct a feature representation of each training tweet (by averaging the word vectors over all words of the tweet).\n",
    "\n",
    "2. Train a Linear Classifier: Train a linear classifier (e.g. logistic regression or SVM) on your constructed features, using the scikit learn library, or your own code from the earlier labs. Recall that the labels indicate if a tweet used to contain a üôÇ or üôÅ smiley.\n",
    "\n",
    "3. Prediction: Predict labels for all tweets in the test set.\n",
    "\n",
    "4. Submission / Evaluation: Submit your predictions to kaggle, and verify the obtained misclassification error score. (You can also use a local separate validation set to get faster feedback on the accuracy of your system). Try to tune your system for best evaluation score.\n",
    "\n",
    "### Extensions:\n",
    "Naturally, there are many ways to improve your solution, both in terms of accuracy and computation speed. More advanced techniques can be found in the recent literature.\n",
    "\n",
    "\n",
    "TODO :\n",
    "\n",
    "- implement cross-validation\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing usefull library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#!/usr/bin/env python3\n",
    "from scipy.sparse import *\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_storing_ts = 'embeddings.npy'\n",
    "file_storing_pos_ts_tweets = 'train_pos.txt'\n",
    "file_storing_neg_ts_tweets = 'train_neg.txt'\n",
    "file_storing_te_tweets = 'test_data.txt'\n",
    "nb_dim = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_embeddings(file_name='cooc.pkl', destination='embeddings.npy'):\n",
    "    print(\"loading cooccurrence matrix\")\n",
    "    with open(file_name, 'rb') as f:\n",
    "        cooc = pickle.load(f)\n",
    "    print(\"{} nonzero entries\".format(cooc.nnz))\n",
    "    \n",
    "    nmax = 100\n",
    "    print(\"using nmax =\", nmax, \", cooc.max() =\", cooc.max())\n",
    "    print(\"initializing embeddings\")\n",
    "    embedding_dim = 20\n",
    "    xs = np.random.normal(size=(cooc.shape[0], embedding_dim))\n",
    "    ys = np.random.normal(size=(cooc.shape[1], embedding_dim))\n",
    "    eta = 0.001\n",
    "    alpha = 3 / 4\n",
    "    epochs = 10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch {}\".format(epoch))\n",
    "        for ix, jy, n in zip(cooc.row, cooc.col, cooc.data):\n",
    "            \n",
    "            f = ((n / nmax)**alpha) if n < nmax else 1\n",
    "            inter_cost = (xs[ix]@(ys[jy]) - np.log(n))\n",
    "            # We compute the gradients for both context and main vector words\n",
    "            grad_main = f * inter_cost * ys[jy]\n",
    "            grad_context = f * inter_cost * xs[ix]\n",
    "    \n",
    "            # Update the vector words\n",
    "            xs[ix] = xs[ix] - (eta * grad_main)\n",
    "            ys[jy] = ys[jy] - (eta * grad_context)\n",
    "            \n",
    "    np.save(destination, xs)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Construct words_embeddings for training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Load words for training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<user>': 0,\n",
       " '!': 1,\n",
       " 'i': 2,\n",
       " 'the': 3,\n",
       " '.': 4,\n",
       " ',': 5,\n",
       " 'to': 6,\n",
       " 'you': 7,\n",
       " '(': 8,\n",
       " '<url>': 9,\n",
       " 'a': 10,\n",
       " '...': 11,\n",
       " 'and': 12,\n",
       " 'my': 13,\n",
       " 'me': 14,\n",
       " 'of': 15,\n",
       " '?': 16,\n",
       " 'is': 17,\n",
       " 'for': 18,\n",
       " 'in': 19,\n",
       " 'it': 20,\n",
       " '\"': 21,\n",
       " 'this': 22,\n",
       " 'so': 23,\n",
       " '-': 24,\n",
       " 'with': 25,\n",
       " 'on': 26,\n",
       " 'that': 27,\n",
       " ')': 28,\n",
       " 'be': 29,\n",
       " \"i'm\": 30,\n",
       " 'have': 31,\n",
       " ':': 32,\n",
       " 'but': 33,\n",
       " 'just': 34,\n",
       " 'rt': 35,\n",
       " 'love': 36,\n",
       " 'your': 37,\n",
       " 'all': 38,\n",
       " 'not': 39,\n",
       " 'was': 40,\n",
       " 'at': 41,\n",
       " 'are': 42,\n",
       " '..': 43,\n",
       " 'like': 44,\n",
       " '/': 45,\n",
       " 'get': 46,\n",
       " 'up': 47,\n",
       " 'frame': 48,\n",
       " '&': 49,\n",
       " 'lol': 50,\n",
       " 'know': 51,\n",
       " 'good': 52,\n",
       " 'do': 53,\n",
       " 'u': 54,\n",
       " 'now': 55,\n",
       " 'when': 56,\n",
       " 'one': 57,\n",
       " 'if': 58,\n",
       " 'we': 59,\n",
       " 'follow': 60,\n",
       " 'no': 61,\n",
       " 'can': 62,\n",
       " 'what': 63,\n",
       " 'go': 64,\n",
       " \"don't\": 65,\n",
       " 'out': 66,\n",
       " 'x': 67,\n",
       " 'will': 68,\n",
       " 'day': 69,\n",
       " \"'\": 70,\n",
       " 'please': 71,\n",
       " 'from': 72,\n",
       " 'see': 73,\n",
       " 'too': 74,\n",
       " 'want': 75,\n",
       " 'there': 76,\n",
       " 'back': 77,\n",
       " \"it's\": 78,\n",
       " 'today': 79,\n",
       " 'about': 80,\n",
       " 'really': 81,\n",
       " 'how': 82,\n",
       " 'got': 83,\n",
       " 'thanks': 84,\n",
       " '2': 85,\n",
       " \"can't\": 86,\n",
       " 'time': 87,\n",
       " 'its': 88,\n",
       " 'think': 89,\n",
       " 'im': 90,\n",
       " '*': 91,\n",
       " 'haha': 92,\n",
       " 'going': 93,\n",
       " 'he': 94,\n",
       " '<3': 95,\n",
       " 'as': 96,\n",
       " 'miss': 97,\n",
       " 'by': 98,\n",
       " 'need': 99,\n",
       " 'an': 100,\n",
       " 'her': 101,\n",
       " 'they': 102,\n",
       " 'or': 103,\n",
       " 'well': 104,\n",
       " 'our': 105,\n",
       " 'why': 106,\n",
       " 'new': 107,\n",
       " 'much': 108,\n",
       " 'she': 109,\n",
       " 'more': 110,\n",
       " 'make': 111,\n",
       " 'paperback': 112,\n",
       " 'would': 113,\n",
       " 'then': 114,\n",
       " 'come': 115,\n",
       " 'some': 116,\n",
       " 'wish': 117,\n",
       " '1': 118,\n",
       " 'oh': 119,\n",
       " 'been': 120,\n",
       " 'only': 121,\n",
       " '3': 122,\n",
       " 'thank': 123,\n",
       " 'who': 124,\n",
       " \"i'll\": 125,\n",
       " 'still': 126,\n",
       " 'had': 127,\n",
       " 'them': 128,\n",
       " 'tomorrow': 129,\n",
       " '>': 130,\n",
       " 'happy': 131,\n",
       " 'right': 132,\n",
       " \"that's\": 133,\n",
       " 'here': 134,\n",
       " 'best': 135,\n",
       " 'never': 136,\n",
       " 'work': 137,\n",
       " 'feel': 138,\n",
       " 'him': 139,\n",
       " 'beautiful': 140,\n",
       " 'hope': 141,\n",
       " 'am': 142,\n",
       " \"you're\": 143,\n",
       " 'has': 144,\n",
       " 'night': 145,\n",
       " 'gonna': 146,\n",
       " 'black': 147,\n",
       " 'home': 148,\n",
       " 'xx': 149,\n",
       " 'people': 150,\n",
       " 'wanna': 151,\n",
       " 'yeah': 152,\n",
       " 'picture': 153,\n",
       " 'off': 154,\n",
       " 'say': 155,\n",
       " 'pack': 156,\n",
       " 'great': 157,\n",
       " 'complete': 158,\n",
       " 'could': 159,\n",
       " 'last': 160,\n",
       " 'school': 161,\n",
       " 'always': 162,\n",
       " 'even': 163,\n",
       " 'life': 164,\n",
       " 'should': 165,\n",
       " 'better': 166,\n",
       " 'us': 167,\n",
       " 'did': 168,\n",
       " 'way': 169,\n",
       " 'sorry': 170,\n",
       " 'tweet': 171,\n",
       " 'wait': 172,\n",
       " 'his': 173,\n",
       " 'take': 174,\n",
       " 'fans': 175,\n",
       " 'xxx': 176,\n",
       " 'girl': 177,\n",
       " '4': 178,\n",
       " 's': 179,\n",
       " 'wide': 180,\n",
       " 'over': 181,\n",
       " 'though': 182,\n",
       " 'tonight': 183,\n",
       " 'hate': 184,\n",
       " 'sad': 185,\n",
       " 'bad': 186,\n",
       " 'poster': 187,\n",
       " 'next': 188,\n",
       " 'again': 189,\n",
       " 'hey': 190,\n",
       " '<': 191,\n",
       " 'yes': 192,\n",
       " 'because': 193,\n",
       " 'baby': 194,\n",
       " 'dont': 195,\n",
       " 'o': 196,\n",
       " 'custom': 197,\n",
       " 'twitter': 198,\n",
       " 'first': 199,\n",
       " 'sleep': 200,\n",
       " 'tell': 201,\n",
       " 'morning': 202,\n",
       " ':d': 203,\n",
       " 'look': 204,\n",
       " 'were': 205,\n",
       " 'where': 206,\n",
       " 'guys': 207,\n",
       " 'birthday': 208,\n",
       " 'nice': 209,\n",
       " 'man': 210,\n",
       " \"i've\": 211,\n",
       " 'ever': 212,\n",
       " 'someone': 213,\n",
       " 'live': 214,\n",
       " 'world': 215,\n",
       " 'little': 216,\n",
       " 'down': 217,\n",
       " 'friends': 218,\n",
       " 'edition': 219,\n",
       " 'something': 220,\n",
       " 'made': 221,\n",
       " 'watch': 222,\n",
       " 'being': 223,\n",
       " 'very': 224,\n",
       " 'after': 225,\n",
       " 'fun': 226,\n",
       " \"didn't\": 227,\n",
       " 'omg': 228,\n",
       " 'phone': 229,\n",
       " 'long': 230,\n",
       " 'getting': 231,\n",
       " 'give': 232,\n",
       " 'video': 233,\n",
       " 'soon': 234,\n",
       " 'okay': 235,\n",
       " 'let': 236,\n",
       " 'than': 237,\n",
       " '6': 238,\n",
       " '5': 239,\n",
       " 'done': 240,\n",
       " 'week': 241,\n",
       " 'same': 242,\n",
       " 'w': 243,\n",
       " 'thing': 244,\n",
       " 'shit': 245,\n",
       " 'ur': 246,\n",
       " 'talk': 247,\n",
       " 'bed': 248,\n",
       " 'cause': 249,\n",
       " 'said': 250,\n",
       " 'year': 251,\n",
       " 'sure': 252,\n",
       " 'everyone': 253,\n",
       " 'cute': 254,\n",
       " 'god': 255,\n",
       " 'any': 256,\n",
       " 'friend': 257,\n",
       " 'amazing': 258,\n",
       " 'these': 259,\n",
       " 'set': 260,\n",
       " 'ok': 261,\n",
       " 'pretty': 262,\n",
       " 'following': 263,\n",
       " 'big': 264,\n",
       " 'keep': 265,\n",
       " 'book': 266,\n",
       " 'game': 267,\n",
       " 'hahaha': 268,\n",
       " 'days': 269,\n",
       " 'hardcover': 270,\n",
       " 'find': 271,\n",
       " 'cant': 272,\n",
       " 'weekend': 273,\n",
       " 'help': 274,\n",
       " 'n': 275,\n",
       " 'white': 276,\n",
       " ';': 277,\n",
       " 'other': 278,\n",
       " 'doing': 279,\n",
       " '10': 280,\n",
       " 'already': 281,\n",
       " 'tho': 282,\n",
       " 'before': 283,\n",
       " 'text': 284,\n",
       " 'call': 285,\n",
       " 'thought': 286,\n",
       " 'case': 287,\n",
       " 'things': 288,\n",
       " 'their': 289,\n",
       " 'show': 290,\n",
       " 'old': 291,\n",
       " 'having': 292,\n",
       " 'everything': 293,\n",
       " 'most': 294,\n",
       " 'series': 295,\n",
       " 'hard': 296,\n",
       " 'cool': 297,\n",
       " 'two': 298,\n",
       " 'mean': 299,\n",
       " 'makes': 300,\n",
       " '#': 301,\n",
       " 'fuck': 302,\n",
       " 'girls': 303,\n",
       " \"won't\": 304,\n",
       " 'dvd': 305,\n",
       " 'another': 306,\n",
       " 'thats': 307,\n",
       " 'stop': 308,\n",
       " 'cd': 309,\n",
       " 'every': 310,\n",
       " 'lmao': 311,\n",
       " 'ill': 312,\n",
       " 'actually': 313,\n",
       " 'hi': 314,\n",
       " '|': 315,\n",
       " 'hair': 316,\n",
       " 'song': 317,\n",
       " 'high': 318,\n",
       " 'music': 319,\n",
       " 'aww': 320,\n",
       " \"what's\": 321,\n",
       " 'may': 322,\n",
       " 'ya': 323,\n",
       " 'try': 324,\n",
       " '12': 325,\n",
       " 'wood': 326,\n",
       " \"he's\": 327,\n",
       " ':p': 328,\n",
       " 'watching': 329,\n",
       " 'must': 330,\n",
       " 'many': 331,\n",
       " 'awesome': 332,\n",
       " 'true': 333,\n",
       " 'looking': 334,\n",
       " 'name': 335,\n",
       " 'away': 336,\n",
       " 'person': 337,\n",
       " 'into': 338,\n",
       " '^': 339,\n",
       " 'via': 340,\n",
       " 'sooo': 341,\n",
       " 'without': 342,\n",
       " 'nothing': 343,\n",
       " 'wrong': 344,\n",
       " 'anything': 345,\n",
       " 'play': 346,\n",
       " 'audio': 347,\n",
       " 'm': 348,\n",
       " 'coming': 349,\n",
       " 'put': 350,\n",
       " 'those': 351,\n",
       " 'b': 352,\n",
       " 'ass': 353,\n",
       " 'yet': 354,\n",
       " 'meet': 355,\n",
       " 'while': 356,\n",
       " \"haven't\": 357,\n",
       " 'since': 358,\n",
       " 'guess': 359,\n",
       " 'feeling': 360,\n",
       " 'face': 361,\n",
       " 'maybe': 362,\n",
       " 'ready': 363,\n",
       " 'followers': 364,\n",
       " 'real': 365,\n",
       " 'smile': 366,\n",
       " 'left': 367,\n",
       " 'cry': 368,\n",
       " 'went': 369,\n",
       " 'heart': 370,\n",
       " 'free': 371,\n",
       " 'stay': 372,\n",
       " 'house': 373,\n",
       " 'friday': 374,\n",
       " 'boys': 375,\n",
       " \"she's\": 376,\n",
       " '8': 377,\n",
       " 'does': 378,\n",
       " 'class': 379,\n",
       " 'use': 380,\n",
       " 'trying': 381,\n",
       " 'also': 382,\n",
       " 'anymore': 383,\n",
       " 'lot': 384,\n",
       " 'saw': 385,\n",
       " 'hot': 386,\n",
       " 'c': 387,\n",
       " 'finally': 388,\n",
       " 'damn': 389,\n",
       " 'missed': 390,\n",
       " 'awww': 391,\n",
       " 'kit': 392,\n",
       " '$': 393,\n",
       " 'such': 394,\n",
       " 'start': 395,\n",
       " '+': 396,\n",
       " 'tired': 397,\n",
       " \"doesn't\": 398,\n",
       " '~': 399,\n",
       " 'tweets': 400,\n",
       " 'r': 401,\n",
       " 't': 402,\n",
       " 'early': 403,\n",
       " 'myself': 404,\n",
       " 'wanted': 405,\n",
       " 'battery': 406,\n",
       " 'funny': 407,\n",
       " 'might': 408,\n",
       " 'red': 409,\n",
       " 'sick': 410,\n",
       " 'around': 411,\n",
       " \"i'd\": 412,\n",
       " 'head': 413,\n",
       " ':/': 414,\n",
       " 'boy': 415,\n",
       " 'mom': 416,\n",
       " 'seeing': 417,\n",
       " 'memory': 418,\n",
       " 'family': 419,\n",
       " 'years': 420,\n",
       " 'through': 421,\n",
       " 'seen': 422,\n",
       " 'end': 423,\n",
       " 'leave': 424,\n",
       " 'excited': 425,\n",
       " 'remember': 426,\n",
       " 'believe': 427,\n",
       " 'd': 428,\n",
       " 'sweet': 429,\n",
       " 'gotta': 430,\n",
       " 'eat': 431,\n",
       " 'making': 432,\n",
       " 'gone': 433,\n",
       " 'inch': 434,\n",
       " 'guide': 435,\n",
       " 'mine': 436,\n",
       " '7': 437,\n",
       " 'care': 438,\n",
       " 'ounce': 439,\n",
       " 'moment': 440,\n",
       " 'glad': 441,\n",
       " 'brand': 442,\n",
       " 'food': 443,\n",
       " 'times': 444,\n",
       " 'brown': 445,\n",
       " 'working': 446,\n",
       " 'perfect': 447,\n",
       " 'share': 448,\n",
       " 'laptop': 449,\n",
       " 'kindle': 450,\n",
       " \"you'll\": 451,\n",
       " 'money': 452,\n",
       " 'mind': 453,\n",
       " 'car': 454,\n",
       " 'read': 455,\n",
       " 'looks': 456,\n",
       " 'whole': 457,\n",
       " 'blue': 458,\n",
       " '[': 459,\n",
       " \"there's\": 460,\n",
       " 'summer': 461,\n",
       " 'talking': 462,\n",
       " 'top': 463,\n",
       " 'lost': 464,\n",
       " 'hear': 465,\n",
       " 'news': 466,\n",
       " 'bit': 467,\n",
       " 'part': 468,\n",
       " 'told': 469,\n",
       " 'luck': 470,\n",
       " 'check': 471,\n",
       " 'aw': 472,\n",
       " 'l': 473,\n",
       " 'ask': 474,\n",
       " '100': 475,\n",
       " 'enough': 476,\n",
       " 'job': 477,\n",
       " 'hours': 478,\n",
       " 'both': 479,\n",
       " 'used': 480,\n",
       " 'anyone': 481,\n",
       " 'team': 482,\n",
       " 'together': 483,\n",
       " 'followed': 484,\n",
       " 'till': 485,\n",
       " 'until': 486,\n",
       " '_': 487,\n",
       " 'full': 488,\n",
       " 'welcome': 489,\n",
       " 'thinking': 490,\n",
       " 'waiting': 491,\n",
       " 'liam': 492,\n",
       " 'babe': 493,\n",
       " 'win': 494,\n",
       " 'later': 495,\n",
       " 'fine': 496,\n",
       " 'ago': 497,\n",
       " 'movie': 498,\n",
       " 'late': 499,\n",
       " 'bitch': 500,\n",
       " 'cold': 501,\n",
       " 'each': 502,\n",
       " 'fan': 503,\n",
       " 'few': 504,\n",
       " 'guy': 505,\n",
       " 'enjoy': 506,\n",
       " 'party': 507,\n",
       " 'story': 508,\n",
       " 'wow': 509,\n",
       " 'lucky': 510,\n",
       " 'change': 511,\n",
       " 'buy': 512,\n",
       " 'which': 513,\n",
       " \"let's\": 514,\n",
       " 'replacement': 515,\n",
       " 'wants': 516,\n",
       " 'favorite': 517,\n",
       " 'bring': 518,\n",
       " 'own': 519,\n",
       " 'dream': 520,\n",
       " 'hp': 521,\n",
       " 'yesterday': 522,\n",
       " ']': 523,\n",
       " 'bout': 524,\n",
       " '9': 525,\n",
       " 'special': 526,\n",
       " 'far': 527,\n",
       " \"isn't\": 528,\n",
       " 'fucking': 529,\n",
       " 'super': 530,\n",
       " 'brother': 531,\n",
       " 'soo': 532,\n",
       " \"they're\": 533,\n",
       " 'once': 534,\n",
       " \"we're\": 535,\n",
       " 'weather': 536,\n",
       " 'stuff': 537,\n",
       " 'rain': 538,\n",
       " 'power': 539,\n",
       " 'hehe': 540,\n",
       " 'justin': 541,\n",
       " 'mad': 542,\n",
       " 'course': 543,\n",
       " 'hell': 544,\n",
       " 'found': 545,\n",
       " 'p': 546,\n",
       " 'words': 547,\n",
       " '=': 548,\n",
       " 'ugh': 549,\n",
       " 'else': 550,\n",
       " 'crazy': 551,\n",
       " 'dear': 552,\n",
       " 'crying': 553,\n",
       " 'boyfriend': 554,\n",
       " 'saturday': 555,\n",
       " 'least': 556,\n",
       " 'almost': 557,\n",
       " 'heard': 558,\n",
       " '16': 559,\n",
       " '(8': 560,\n",
       " 'probably': 561,\n",
       " 'sucks': 562,\n",
       " '20': 563,\n",
       " 'goes': 564,\n",
       " 'everyday': 565,\n",
       " 'proud': 566,\n",
       " 'place': 567,\n",
       " \"wasn't\": 568,\n",
       " 'able': 569,\n",
       " 'single': 570,\n",
       " 'room': 571,\n",
       " 'ipod': 572,\n",
       " 'health': 573,\n",
       " 'alone': 574,\n",
       " 'size': 575,\n",
       " 'lovely': 576,\n",
       " 'shoutout': 577,\n",
       " 'sexy': 578,\n",
       " 'seriously': 579,\n",
       " 'f': 580,\n",
       " 'camera': 581,\n",
       " 'sounds': 582,\n",
       " 'ha': 583,\n",
       " 'weeks': 584,\n",
       " 'playing': 585,\n",
       " 'hurt': 586,\n",
       " 'came': 587,\n",
       " 'loves': 588,\n",
       " 'boo': 589,\n",
       " 'oz': 590,\n",
       " 'reply': 591,\n",
       " 'second': 592,\n",
       " 'hit': 593,\n",
       " 'green': 594,\n",
       " 'forever': 595,\n",
       " 'poor': 596,\n",
       " 'eyes': 597,\n",
       " '%': 598,\n",
       " 'yea': 599,\n",
       " 'idk': 600,\n",
       " 'gets': 601,\n",
       " 'dad': 602,\n",
       " 'walk': 603,\n",
       " 'hello': 604,\n",
       " 'body': 605,\n",
       " 'cable': 606,\n",
       " 'send': 607,\n",
       " 'date': 608,\n",
       " 'small': 609,\n",
       " 'stupid': 610,\n",
       " 'sister': 611,\n",
       " 'saying': 612,\n",
       " 'notice': 613,\n",
       " 'didnt': 614,\n",
       " 'yay': 615,\n",
       " 'english': 616,\n",
       " 'forget': 617,\n",
       " 'comes': 618,\n",
       " 'beauty': 619,\n",
       " 'number': 620,\n",
       " 'ima': 621,\n",
       " 'digital': 622,\n",
       " 'tickets': 623,\n",
       " 'pic': 624,\n",
       " 'photo': 625,\n",
       " 'kids': 626,\n",
       " 'ram': 627,\n",
       " 'album': 628,\n",
       " 'voice': 629,\n",
       " 'lil': 630,\n",
       " 'pain': 631,\n",
       " 'bored': 632,\n",
       " 'woke': 633,\n",
       " 'ah': 634,\n",
       " 'color': 635,\n",
       " 'retweet': 636,\n",
       " 'needs': 637,\n",
       " 'nooo': 638,\n",
       " 'missing': 639,\n",
       " 'na': 640,\n",
       " 'season': 641,\n",
       " 'run': 642,\n",
       " 'american': 643,\n",
       " 'hurts': 644,\n",
       " 'hopefully': 645,\n",
       " '18': 646,\n",
       " 'city': 647,\n",
       " 'dm': 648,\n",
       " 'chance': 649,\n",
       " 'half': 650,\n",
       " 'wrote': 651,\n",
       " '30': 652,\n",
       " \"couldn't\": 653,\n",
       " 'took': 654,\n",
       " 'drive': 655,\n",
       " 'classic': 656,\n",
       " 'word': 657,\n",
       " 'light': 658,\n",
       " 'cuz': 659,\n",
       " 'concert': 660,\n",
       " 'wake': 661,\n",
       " 'sometimes': 662,\n",
       " 'forward': 663,\n",
       " '2012': 664,\n",
       " 'rest': 665,\n",
       " \"ain't\": 666,\n",
       " 'hour': 667,\n",
       " 'prom': 668,\n",
       " 'y': 669,\n",
       " 'silver': 670,\n",
       " 'steel': 671,\n",
       " 'means': 672,\n",
       " 'dance': 673,\n",
       " 'bag': 674,\n",
       " 'cat': 675,\n",
       " 'tv': 676,\n",
       " 'dress': 677,\n",
       " 'dog': 678,\n",
       " 'count': 679,\n",
       " 'called': 680,\n",
       " 'month': 681,\n",
       " 'goodnight': 682,\n",
       " 'easy': 683,\n",
       " 'product': 684,\n",
       " 'niall': 685,\n",
       " 'hologram': 686,\n",
       " 'forgot': 687,\n",
       " 'a-tech': 688,\n",
       " 'kitchen': 689,\n",
       " 'touch': 690,\n",
       " 'th': 691,\n",
       " 'happen': 692,\n",
       " 'bro': 693,\n",
       " 'worst': 694,\n",
       " 'side': 695,\n",
       " 'ones': 696,\n",
       " 'history': 697,\n",
       " 'hand': 698,\n",
       " 'taking': 699,\n",
       " \"we'll\": 700,\n",
       " 'listen': 701,\n",
       " 'skin': 702,\n",
       " 'notebook': 703,\n",
       " 'dark': 704,\n",
       " 'business': 705,\n",
       " 'reason': 706,\n",
       " 'sound': 707,\n",
       " 'hahah': 708,\n",
       " 'leaving': 709,\n",
       " 'cover': 710,\n",
       " 'problem': 711,\n",
       " 'yo': 712,\n",
       " 'laugh': 713,\n",
       " 'three': 714,\n",
       " 'either': 715,\n",
       " 'box': 716,\n",
       " 'move': 717,\n",
       " 'games': 718,\n",
       " 'young': 719,\n",
       " 'wont': 720,\n",
       " 'wit': 721,\n",
       " 'btw': 722,\n",
       " 'turn': 723,\n",
       " 'says': 724,\n",
       " 'outside': 725,\n",
       " 'lunch': 726,\n",
       " 'feet': 727,\n",
       " 'trip': 728,\n",
       " 'close': 729,\n",
       " 'ahhh': 730,\n",
       " 'worry': 731,\n",
       " 'idea': 732,\n",
       " '15': 733,\n",
       " 'point': 734,\n",
       " 'jealous': 735,\n",
       " 'electronics': 736,\n",
       " 'card': 737,\n",
       " '@': 738,\n",
       " 'h': 739,\n",
       " 'online': 740,\n",
       " 'screen': 741,\n",
       " 'harry': 742,\n",
       " '11': 743,\n",
       " 'tour': 744,\n",
       " 'listening': 745,\n",
       " 'open': 746,\n",
       " 'mood': 747,\n",
       " 'songs': 748,\n",
       " 'knew': 749,\n",
       " 'fall': 750,\n",
       " 'met': 751,\n",
       " 'la': 752,\n",
       " 'die': 753,\n",
       " 'wear': 754,\n",
       " 'study': 755,\n",
       " 'e': 756,\n",
       " \"y'all\": 757,\n",
       " 'test': 758,\n",
       " 'short': 759,\n",
       " 'plus': 760,\n",
       " 'pick': 761,\n",
       " 'official': 762,\n",
       " 'design': 763,\n",
       " 'college': 764,\n",
       " 'alright': 765,\n",
       " 'k': 766,\n",
       " 'finish': 767,\n",
       " 'busy': 768,\n",
       " 'cut': 769,\n",
       " 'art': 770,\n",
       " 'nobody': 771,\n",
       " 'dinner': 772,\n",
       " 'toy': 773,\n",
       " 'style': 774,\n",
       " 'ddr': 775,\n",
       " \"you've\": 776,\n",
       " 'understand': 777,\n",
       " 'smh': 778,\n",
       " 'scared': 779,\n",
       " 'paper': 780,\n",
       " 'kind': 781,\n",
       " 'yourself': 782,\n",
       " 'pink': 783,\n",
       " 'fast': 784,\n",
       " 'v': 785,\n",
       " 'started': 786,\n",
       " 'release': 787,\n",
       " 'manufactured': 788,\n",
       " 'feels': 789,\n",
       " 'facebook': 790,\n",
       " 'reading': 791,\n",
       " 'kinda': 792,\n",
       " '50': 793,\n",
       " 'sun': 794,\n",
       " 'support': 795,\n",
       " 'mum': 796,\n",
       " 'account': 797,\n",
       " 'post': 798,\n",
       " 'inside': 799,\n",
       " 'uk': 800,\n",
       " 'months': 801,\n",
       " 'collection': 802,\n",
       " 'bet': 803,\n",
       " 'sports': 804,\n",
       " 'leather': 805,\n",
       " 'em': 806,\n",
       " 'aint': 807,\n",
       " 'direction': 808,\n",
       " 'bus': 809,\n",
       " 'break': 810,\n",
       " 'shout': 811,\n",
       " 'gave': 812,\n",
       " \"who's\": 813,\n",
       " 'yours': 814,\n",
       " 'loved': 815,\n",
       " 'happened': 816,\n",
       " 'gold': 817,\n",
       " 'somebody': 818,\n",
       " 'g': 819,\n",
       " 'yu': 820,\n",
       " 'ice': 821,\n",
       " 'wall': 822,\n",
       " 'totally': 823,\n",
       " 'market': 824,\n",
       " 'louis': 825,\n",
       " 'chocolate': 826,\n",
       " 'fat': 827,\n",
       " 'past': 828,\n",
       " 'rock': 829,\n",
       " 'pair': 830,\n",
       " 'join': 831,\n",
       " 'double': 832,\n",
       " 'ma': 833,\n",
       " 'coffee': 834,\n",
       " 'apple': 835,\n",
       " 'lady': 836,\n",
       " 'tried': 837,\n",
       " 'definitely': 838,\n",
       " 'sunday': 839,\n",
       " 'plan': 840,\n",
       " 'death': 841,\n",
       " 'smoking': 842,\n",
       " 'dead': 843,\n",
       " 'save': 844,\n",
       " '\\\\': 845,\n",
       " '#ff': 846,\n",
       " 'sex': 847,\n",
       " 'pro': 848,\n",
       " 'monday': 849,\n",
       " 'water': 850,\n",
       " 'system': 851,\n",
       " 'eating': 852,\n",
       " '1gb': 853,\n",
       " 'dude': 854,\n",
       " '4/20': 855,\n",
       " 'round': 856,\n",
       " 'london': 857,\n",
       " 'hug': 858,\n",
       " 'cream': 859,\n",
       " 'anyway': 860,\n",
       " 'asleep': 861,\n",
       " '24': 862,\n",
       " 'learn': 863,\n",
       " 'upgrade': 864,\n",
       " 'seems': 865,\n",
       " 'quality': 866,\n",
       " 'future': 867,\n",
       " 'deal': 868,\n",
       " 'country': 869,\n",
       " 'pictures': 870,\n",
       " 'original': 871,\n",
       " 'matter': 872,\n",
       " 'instead': 873,\n",
       " 'everybody': 874,\n",
       " 'compatible': 875,\n",
       " 'april': 876,\n",
       " 'zayn': 877,\n",
       " 'ugly': 878,\n",
       " 'kill': 879,\n",
       " 'iphone': 880,\n",
       " 'stories': 881,\n",
       " 'nd': 882,\n",
       " 'air': 883,\n",
       " 'usb': 884,\n",
       " 'longer': 885,\n",
       " 'lets': 886,\n",
       " 'clear': 887,\n",
       " 'catch': 888,\n",
       " 'books': 889,\n",
       " 'congrats': 890,\n",
       " 'broke': 891,\n",
       " 'line': 892,\n",
       " 'hahahaha': 893,\n",
       " 'died': 894,\n",
       " \":')\": 895,\n",
       " 'tweeting': 896,\n",
       " 'practice': 897,\n",
       " 'page': 898,\n",
       " 'minutes': 899,\n",
       " 'hungry': 900,\n",
       " '#oomf': 901,\n",
       " 'travel': 902,\n",
       " 'living': 903,\n",
       " 'takes': 904,\n",
       " 'knows': 905,\n",
       " 'kid': 906,\n",
       " 'lmfao': 907,\n",
       " 'kiss': 908,\n",
       " 'imma': 909,\n",
       " \"wouldn't\": 910,\n",
       " 'twitcam': 911,\n",
       " 'ahh': 912,\n",
       " 'personal': 913,\n",
       " 'drink': 914,\n",
       " 'da': 915,\n",
       " 'band': 916,\n",
       " 'answer': 917,\n",
       " 'goin': 918,\n",
       " 'finished': 919,\n",
       " 'exactly': 920,\n",
       " 'blow': 921,\n",
       " '25': 922,\n",
       " 'yellow': 923,\n",
       " 'smoke': 924,\n",
       " 'exam': 925,\n",
       " 'wonder': 926,\n",
       " 'press': 927,\n",
       " 'ive': 928,\n",
       " 'pm': 929,\n",
       " 'mate': 930,\n",
       " 'asked': 931,\n",
       " 'visit': 932,\n",
       " 'tea': 933,\n",
       " 'front': 934,\n",
       " 'star': 935,\n",
       " 'ohh': 936,\n",
       " 'different': 937,\n",
       " 'under': 938,\n",
       " 'ppl': 939,\n",
       " 'lots': 940,\n",
       " 'thursday': 941,\n",
       " 'sold': 942,\n",
       " 'hang': 943,\n",
       " 'shower': 944,\n",
       " 'pls': 945,\n",
       " 'yall': 946,\n",
       " \"women's\": 947,\n",
       " 'running': 948,\n",
       " 'loool': 949,\n",
       " 'aha': 950,\n",
       " 'road': 951,\n",
       " 'fact': 952,\n",
       " 'cell': 953,\n",
       " 'bought': 954,\n",
       " 'parents': 955,\n",
       " 'gym': 956,\n",
       " 'version': 957,\n",
       " 'includes': 958,\n",
       " 'couple': 959,\n",
       " 'club': 960,\n",
       " 'blog': 961,\n",
       " '1d': 962,\n",
       " 'agree': 963,\n",
       " 'sleeping': 964,\n",
       " 'large': 965,\n",
       " 'compaq': 966,\n",
       " 'wonderful': 967,\n",
       " 'stand': 968,\n",
       " 'misc': 969,\n",
       " 'bestfriend': 970,\n",
       " 'loving': 971,\n",
       " 'between': 972,\n",
       " 'write': 973,\n",
       " 'ball': 974,\n",
       " 'town': 975,\n",
       " 'print': 976,\n",
       " 'jus': 977,\n",
       " 'xd': 978,\n",
       " 'volume': 979,\n",
       " 'office': 980,\n",
       " 'length': 981,\n",
       " 'dreams': 982,\n",
       " 'tears': 983,\n",
       " 'radio': 984,\n",
       " 'fit': 985,\n",
       " 'adapter': 986,\n",
       " 'worth': 987,\n",
       " 'shirt': 988,\n",
       " 'performance': 989,\n",
       " 'weird': 990,\n",
       " 'swear': 991,\n",
       " 'french': 992,\n",
       " 'whats': 993,\n",
       " 'hold': 994,\n",
       " 'starting': 995,\n",
       " 'beach': 996,\n",
       " 'bday': 997,\n",
       " 'youuu': 998,\n",
       " 'women': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('vocab.pkl', 'rb') as f :\n",
    "    vocab = pickle.load(f)\n",
    "xs = np.load(file_storing_ts)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3.Construct features for training tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tweets = open(file_storing_pos_ts_tweets, 'r').readlines() \n",
    "neg_tweets = open(file_storing_neg_ts_tweets, 'r').readlines()\n",
    "\n",
    "\n",
    "#Construct features for positive tweets\n",
    "pos_features = []\n",
    "\n",
    "for line in pos_tweets:\n",
    "    sum_w = np.zeros(nb_dim)\n",
    "    count = 0\n",
    "    for word in line.split():\n",
    "        local_w = vocab.get(word, -1)\n",
    "        if local_w != -1:\n",
    "            count += 1\n",
    "            sum_w += xs[local_w]\n",
    "     \n",
    "    # If no match between the vocab and the tweet, we set the feature vector to zeros (zero best value ?)\n",
    "    if(count == 0):\n",
    "        count = 1\n",
    "    pos_features.append(sum_w/count)\n",
    "pos_features = np.array(pos_features)    \n",
    "    \n",
    "#Construct features for negative tweets\n",
    "neg_features = []\n",
    "\n",
    "for line in neg_tweets:\n",
    "    sum_w = np.zeros(nb_dim)\n",
    "    count = 0\n",
    "    for word in line.split():\n",
    "        local_w = vocab.get(word, -1)\n",
    "        if local_w != -1:\n",
    "            count += 1\n",
    "            sum_w += xs[local_w]\n",
    "     \n",
    "    # If no match between the vocab and the tweet, we set the feature vector to zeros (zero best value ?)\n",
    "    if(count == 0):\n",
    "        count = 1\n",
    "    neg_features.append(sum_w/count)\n",
    "    \n",
    "neg_features = np.array(neg_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Train the linear classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(n_iter=50, warm_start=True);\n",
    "X = np.concatenate((pos_features, neg_features))\n",
    "scaler = preprocessing.StandardScaler()\n",
    "Y = np.concatenate((np.ones(len(pos_features)), np.full(len(neg_features), -1)))\n",
    "X = scaler.fit_transform(X, Y)\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  61.4925 %\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy : \", (1 - (np.sum(np.abs(Y-prediction))/(2*200000))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
