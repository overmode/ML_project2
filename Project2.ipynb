{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Note book for the project 2 \n",
    "\n",
    "Kaggle competition link: [Submition]('https://www.kaggle.com/c/epfml17-text/submit')\n",
    "\n",
    "## Pipeline: \n",
    "\n",
    "\n",
    "### Create cooc matrix\n",
    "\n",
    "1. sh build_vocab.sh\n",
    "2. sh cut_vocab.sh\n",
    "3. python3 pickle_vocab.py\n",
    "4. python3 cooc.py\n",
    "\n",
    "Now given the co-occurrence matrix and the vocabulary, it is not hard to train GloVe word embeddings, that is to compute an embedding vector for wach word in the vocabulary. We suggest to implement SGD updates to train the matrix factorization, as in\n",
    "\n",
    "5. python3 glove_template.py\n",
    "\n",
    "Once you tested your system on the small set of 10% of all tweets, we suggest you run on the full datasets pos_train_full.txt, neg_train_full.txt\n",
    "\n",
    "### Building a Text Classifier:\n",
    "\n",
    "1. Construct Features for the Training Texts: Load the training tweets and the built GloVe word embeddings. Using the word embeddings, construct a feature representation of each training tweet (by averaging the word vectors over all words of the tweet).\n",
    "\n",
    "2. Train a Linear Classifier: Train a linear classifier (e.g. logistic regression or SVM) on your constructed features, using the scikit learn library, or your own code from the earlier labs. Recall that the labels indicate if a tweet used to contain a üôÇ or üôÅ smiley.\n",
    "\n",
    "3. Prediction: Predict labels for all tweets in the test set.\n",
    "\n",
    "4. Submission / Evaluation: Submit your predictions to kaggle, and verify the obtained misclassification error score. (You can also use a local separate validation set to get faster feedback on the accuracy of your system). Try to tune your system for best evaluation score.\n",
    "\n",
    "### Extensions:\n",
    "Naturally, there are many ways to improve your solution, both in terms of accuracy and computation speed. More advanced techniques can be found in the recent literature.\n",
    "\n",
    "\n",
    "TODO :\n",
    "\n",
    "- implement cross-validation\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing usefull library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#!/usr/bin/env python3\n",
    "from scipy.sparse import *\n",
    "from sklearn import linear_model, preprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_storing_ts = 'embeddings_full.npy'\n",
    "file_storing_pos_ts_tweets = 'train_pos_full.txt'\n",
    "file_storing_neg_ts_tweets = 'train_neg_full.txt'\n",
    "file_storing_te_tweets = 'test_data.txt'\n",
    "nb_dim = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embeddings(file_name='cooc_full.pkl', destination = file_storing_ts):\n",
    "    print(\"loading cooccurrence matrix\")\n",
    "    with open(file_name, 'rb') as f:\n",
    "        cooc = pickle.load(f)\n",
    "    print(\"{} nonzero entries\".format(cooc.nnz))\n",
    "    \n",
    "    nmax = 100\n",
    "    print(\"using nmax =\", nmax, \", cooc.max() =\", cooc.max())\n",
    "    print(\"initializing embeddings\")\n",
    "    embedding_dim = 20\n",
    "    xs = np.random.normal(size=(cooc.shape[0], embedding_dim))\n",
    "    ys = np.random.normal(size=(cooc.shape[1], embedding_dim))\n",
    "    eta = 0.001\n",
    "    alpha = 3 / 4\n",
    "    epochs = 3\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch {}\".format(epoch))\n",
    "        for ix, jy, n in zip(cooc.row, cooc.col, cooc.data):\n",
    "            \n",
    "            f = ((n / nmax)**alpha) if n < nmax else 1\n",
    "            inter_cost = (xs[ix]@(ys[jy]) - np.log(n))\n",
    "            # We compute the gradients for both context and main vector words\n",
    "            grad_main = f * inter_cost * ys[jy]\n",
    "            grad_context = f * inter_cost * xs[ix]\n",
    "    \n",
    "            # Update the vector words\n",
    "            xs[ix] = xs[ix] - (eta * grad_main)\n",
    "            ys[jy] = ys[jy] - (eta * grad_context)\n",
    "            \n",
    "    np.save(destination, xs)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Construct words_embeddings for training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooccurrence matrix\n",
      "46597044 nonzero entries\n",
      "using nmax = 100 , cooc.max() = 2599902\n",
      "initializing embeddings\n",
      "epoch 0\n",
      "epoch 1\n",
      "epoch 2\n"
     ]
    }
   ],
   "source": [
    "word_embeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Load words for training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<user>': 0,\n",
       " '!': 1,\n",
       " 'i': 2,\n",
       " 'the': 3,\n",
       " '.': 4,\n",
       " ',': 5,\n",
       " 'to': 6,\n",
       " 'you': 7,\n",
       " '(': 8,\n",
       " '<url>': 9,\n",
       " 'a': 10,\n",
       " '...': 11,\n",
       " 'and': 12,\n",
       " 'my': 13,\n",
       " 'me': 14,\n",
       " 'of': 15,\n",
       " '?': 16,\n",
       " 'is': 17,\n",
       " 'for': 18,\n",
       " 'in': 19,\n",
       " 'it': 20,\n",
       " '\"': 21,\n",
       " 'this': 22,\n",
       " 'on': 23,\n",
       " 'with': 24,\n",
       " 'that': 25,\n",
       " 'so': 26,\n",
       " '-': 27,\n",
       " ')': 28,\n",
       " 'be': 29,\n",
       " 'have': 30,\n",
       " \"i'm\": 31,\n",
       " ':': 32,\n",
       " 'but': 33,\n",
       " 'just': 34,\n",
       " 'rt': 35,\n",
       " 'your': 36,\n",
       " 'love': 37,\n",
       " 'not': 38,\n",
       " 'was': 39,\n",
       " 'are': 40,\n",
       " '..': 41,\n",
       " 'like': 42,\n",
       " 'at': 43,\n",
       " 'all': 44,\n",
       " '/': 45,\n",
       " 'get': 46,\n",
       " 'frame': 47,\n",
       " 'up': 48,\n",
       " '&': 49,\n",
       " 'u': 50,\n",
       " 'lol': 51,\n",
       " 'good': 52,\n",
       " 'know': 53,\n",
       " 'do': 54,\n",
       " 'when': 55,\n",
       " 'one': 56,\n",
       " 'now': 57,\n",
       " 'we': 58,\n",
       " 'follow': 59,\n",
       " 'if': 60,\n",
       " 'no': 61,\n",
       " 'can': 62,\n",
       " 'go': 63,\n",
       " \"don't\": 64,\n",
       " 'what': 65,\n",
       " 'will': 66,\n",
       " 'out': 67,\n",
       " 'please': 68,\n",
       " 'day': 69,\n",
       " 'too': 70,\n",
       " 'from': 71,\n",
       " 'see': 72,\n",
       " 'want': 73,\n",
       " \"'\": 74,\n",
       " 'back': 75,\n",
       " \"it's\": 76,\n",
       " 'thanks': 77,\n",
       " 'how': 78,\n",
       " 'x': 79,\n",
       " 'about': 80,\n",
       " 'time': 81,\n",
       " 'got': 82,\n",
       " 'really': 83,\n",
       " 'its': 84,\n",
       " '2': 85,\n",
       " 'today': 86,\n",
       " \"can't\": 87,\n",
       " 'im': 88,\n",
       " 'haha': 89,\n",
       " '<3': 90,\n",
       " 'he': 91,\n",
       " 'going': 92,\n",
       " 'think': 93,\n",
       " 'as': 94,\n",
       " '*': 95,\n",
       " 'her': 96,\n",
       " 'miss': 97,\n",
       " 'an': 98,\n",
       " 'there': 99,\n",
       " 'they': 100,\n",
       " 'new': 101,\n",
       " 'need': 102,\n",
       " 'much': 103,\n",
       " 'why': 104,\n",
       " 'or': 105,\n",
       " 'by': 106,\n",
       " 'she': 107,\n",
       " 'well': 108,\n",
       " 'would': 109,\n",
       " 'make': 110,\n",
       " 'more': 111,\n",
       " 'then': 112,\n",
       " 'paperback': 113,\n",
       " 'some': 114,\n",
       " 'come': 115,\n",
       " 'only': 116,\n",
       " 'been': 117,\n",
       " 'had': 118,\n",
       " 'still': 119,\n",
       " 'them': 120,\n",
       " '>': 121,\n",
       " 'who': 122,\n",
       " 'oh': 123,\n",
       " \"i'll\": 124,\n",
       " 'thank': 125,\n",
       " 'night': 126,\n",
       " 'never': 127,\n",
       " 'wish': 128,\n",
       " 'best': 129,\n",
       " 'happy': 130,\n",
       " 'right': 131,\n",
       " '3': 132,\n",
       " '1': 133,\n",
       " 'tomorrow': 134,\n",
       " 'here': 135,\n",
       " 'work': 136,\n",
       " 'him': 137,\n",
       " \"that's\": 138,\n",
       " 'hope': 139,\n",
       " 'feel': 140,\n",
       " 'am': 141,\n",
       " 'has': 142,\n",
       " 'people': 143,\n",
       " \"you're\": 144,\n",
       " 'black': 145,\n",
       " 'yeah': 146,\n",
       " 'gonna': 147,\n",
       " 'wanna': 148,\n",
       " 'say': 149,\n",
       " 'picture': 150,\n",
       " 'xx': 151,\n",
       " 'off': 152,\n",
       " 'home': 153,\n",
       " 'pack': 154,\n",
       " 'complete': 155,\n",
       " 'life': 156,\n",
       " 'school': 157,\n",
       " 'great': 158,\n",
       " 'should': 159,\n",
       " 'always': 160,\n",
       " 'did': 161,\n",
       " 'last': 162,\n",
       " 'way': 163,\n",
       " 'could': 164,\n",
       " 'our': 165,\n",
       " 'wait': 166,\n",
       " 'even': 167,\n",
       " 'better': 168,\n",
       " 'us': 169,\n",
       " 'his': 170,\n",
       " 'girl': 171,\n",
       " '4': 172,\n",
       " 'sorry': 173,\n",
       " 'xxx': 174,\n",
       " 'wide': 175,\n",
       " 'tonight': 176,\n",
       " 'take': 177,\n",
       " 'hey': 178,\n",
       " '<': 179,\n",
       " 'bad': 180,\n",
       " 'hate': 181,\n",
       " 'poster': 182,\n",
       " 'though': 183,\n",
       " 's': 184,\n",
       " 'because': 185,\n",
       " 'sad': 186,\n",
       " 'tweet': 187,\n",
       " 'dont': 188,\n",
       " 'over': 189,\n",
       " 'again': 190,\n",
       " 'o': 191,\n",
       " 'first': 192,\n",
       " 'next': 193,\n",
       " 'look': 194,\n",
       " 'yes': 195,\n",
       " 'baby': 196,\n",
       " 'custom': 197,\n",
       " 'sleep': 198,\n",
       " 'morning': 199,\n",
       " ':d': 200,\n",
       " 'nice': 201,\n",
       " 'twitter': 202,\n",
       " 'birthday': 203,\n",
       " 'were': 204,\n",
       " \"i've\": 205,\n",
       " 'man': 206,\n",
       " 'guys': 207,\n",
       " 'friends': 208,\n",
       " 'edition': 209,\n",
       " 'where': 210,\n",
       " 'someone': 211,\n",
       " 'very': 212,\n",
       " 'live': 213,\n",
       " 'little': 214,\n",
       " 'ever': 215,\n",
       " 'phone': 216,\n",
       " 'down': 217,\n",
       " 'made': 218,\n",
       " 'omg': 219,\n",
       " \"didn't\": 220,\n",
       " 'being': 221,\n",
       " 'world': 222,\n",
       " 'watch': 223,\n",
       " 'tell': 224,\n",
       " 'getting': 225,\n",
       " 'than': 226,\n",
       " '5': 227,\n",
       " 'fun': 228,\n",
       " 'after': 229,\n",
       " 'everyone': 230,\n",
       " 'let': 231,\n",
       " 'something': 232,\n",
       " 'okay': 233,\n",
       " 'give': 234,\n",
       " 'same': 235,\n",
       " 'long': 236,\n",
       " 'soon': 237,\n",
       " 'week': 238,\n",
       " '6': 239,\n",
       " 'amazing': 240,\n",
       " 'video': 241,\n",
       " 'said': 242,\n",
       " 'year': 243,\n",
       " 'thing': 244,\n",
       " 'ur': 245,\n",
       " 'w': 246,\n",
       " 'bed': 247,\n",
       " 'shit': 248,\n",
       " 'any': 249,\n",
       " 'beautiful': 250,\n",
       " 'talk': 251,\n",
       " 'sure': 252,\n",
       " 'done': 253,\n",
       " 'set': 254,\n",
       " 'friend': 255,\n",
       " 'book': 256,\n",
       " 'cute': 257,\n",
       " 'big': 258,\n",
       " 'hahaha': 259,\n",
       " 'cause': 260,\n",
       " 'keep': 261,\n",
       " 'game': 262,\n",
       " 'ok': 263,\n",
       " 'following': 264,\n",
       " ';': 265,\n",
       " 'other': 266,\n",
       " 'pretty': 267,\n",
       " 'these': 268,\n",
       " 'hardcover': 269,\n",
       " 'days': 270,\n",
       " 'doing': 271,\n",
       " 'white': 272,\n",
       " 'weekend': 273,\n",
       " 'tho': 274,\n",
       " 'things': 275,\n",
       " 'help': 276,\n",
       " 'text': 277,\n",
       " 'god': 278,\n",
       " 'show': 279,\n",
       " 'cant': 280,\n",
       " 'n': 281,\n",
       " 'everything': 282,\n",
       " '10': 283,\n",
       " 'already': 284,\n",
       " 'thought': 285,\n",
       " 'their': 286,\n",
       " 'most': 287,\n",
       " 'before': 288,\n",
       " 'every': 289,\n",
       " 'call': 290,\n",
       " 'series': 291,\n",
       " 'hi': 292,\n",
       " 'dvd': 293,\n",
       " 'fuck': 294,\n",
       " 'find': 295,\n",
       " 'mean': 296,\n",
       " 'two': 297,\n",
       " 'hard': 298,\n",
       " 'ill': 299,\n",
       " 'makes': 300,\n",
       " 'case': 301,\n",
       " \"won't\": 302,\n",
       " '|': 303,\n",
       " 'old': 304,\n",
       " 'high': 305,\n",
       " 'girls': 306,\n",
       " 'having': 307,\n",
       " 'actually': 308,\n",
       " 'cool': 309,\n",
       " 'cd': 310,\n",
       " 'another': 311,\n",
       " \"he's\": 312,\n",
       " 'watching': 313,\n",
       " 'ya': 314,\n",
       " 'song': 315,\n",
       " 'away': 316,\n",
       " 'looking': 317,\n",
       " 'wood': 318,\n",
       " 'try': 319,\n",
       " 'music': 320,\n",
       " 'lmao': 321,\n",
       " 'b': 322,\n",
       " 'coming': 323,\n",
       " '^': 324,\n",
       " 'feeling': 325,\n",
       " 'aww': 326,\n",
       " 'may': 327,\n",
       " '12': 328,\n",
       " 'stop': 329,\n",
       " ':p': 330,\n",
       " 'hair': 331,\n",
       " 'thats': 332,\n",
       " 'without': 333,\n",
       " 'nothing': 334,\n",
       " 'true': 335,\n",
       " 'via': 336,\n",
       " 'awesome': 337,\n",
       " 'face': 338,\n",
       " 'into': 339,\n",
       " 'm': 340,\n",
       " 'sooo': 341,\n",
       " 'maybe': 342,\n",
       " 'must': 343,\n",
       " 'ready': 344,\n",
       " 'many': 345,\n",
       " 'those': 346,\n",
       " 'guess': 347,\n",
       " 'put': 348,\n",
       " 'smile': 349,\n",
       " 'play': 350,\n",
       " '+': 351,\n",
       " 'since': 352,\n",
       " 'audio': 353,\n",
       " 'house': 354,\n",
       " 'meet': 355,\n",
       " 'ass': 356,\n",
       " 't': 357,\n",
       " 'friday': 358,\n",
       " '#': 359,\n",
       " 'heart': 360,\n",
       " 'real': 361,\n",
       " 'anything': 362,\n",
       " 'while': 363,\n",
       " 'followers': 364,\n",
       " 'name': 365,\n",
       " 'yet': 366,\n",
       " \"she's\": 367,\n",
       " \"haven't\": 368,\n",
       " 'such': 369,\n",
       " 'does': 370,\n",
       " 'damn': 371,\n",
       " 'boys': 372,\n",
       " 'free': 373,\n",
       " 'awww': 374,\n",
       " 'use': 375,\n",
       " 'left': 376,\n",
       " 'class': 377,\n",
       " 'cry': 378,\n",
       " 'lot': 379,\n",
       " 'went': 380,\n",
       " 'hot': 381,\n",
       " 'start': 382,\n",
       " 'head': 383,\n",
       " 'boy': 384,\n",
       " 'mom': 385,\n",
       " '8': 386,\n",
       " 'r': 387,\n",
       " 'c': 388,\n",
       " 'leave': 389,\n",
       " 'wanted': 390,\n",
       " 'person': 391,\n",
       " 'd': 392,\n",
       " 'myself': 393,\n",
       " 'saw': 394,\n",
       " 'end': 395,\n",
       " 'red': 396,\n",
       " 'tweets': 397,\n",
       " '$': 398,\n",
       " 'funny': 399,\n",
       " \"doesn't\": 400,\n",
       " 'kit': 401,\n",
       " 'also': 402,\n",
       " 'finally': 403,\n",
       " \"what's\": 404,\n",
       " '~': 405,\n",
       " 'might': 406,\n",
       " 'tired': 407,\n",
       " 'missed': 408,\n",
       " 'battery': 409,\n",
       " 'sick': 410,\n",
       " 'anymore': 411,\n",
       " 'trying': 412,\n",
       " 'stay': 413,\n",
       " 'mine': 414,\n",
       " 'around': 415,\n",
       " 'years': 416,\n",
       " 'family': 417,\n",
       " 'care': 418,\n",
       " 'gone': 419,\n",
       " 'excited': 420,\n",
       " 'believe': 421,\n",
       " 'memory': 422,\n",
       " 'wrong': 423,\n",
       " 'gotta': 424,\n",
       " 'early': 425,\n",
       " 'eat': 426,\n",
       " 'perfect': 427,\n",
       " 'mind': 428,\n",
       " 'making': 429,\n",
       " \"i'd\": 430,\n",
       " 'sweet': 431,\n",
       " 'fans': 432,\n",
       " 'car': 433,\n",
       " 'through': 434,\n",
       " 'times': 435,\n",
       " 'check': 436,\n",
       " 'seen': 437,\n",
       " 'ounce': 438,\n",
       " ':/': 439,\n",
       " 'blue': 440,\n",
       " 'top': 441,\n",
       " 'brand': 442,\n",
       " 'food': 443,\n",
       " 'glad': 444,\n",
       " 'news': 445,\n",
       " 'inch': 446,\n",
       " 'remember': 447,\n",
       " 'looks': 448,\n",
       " 'read': 449,\n",
       " '[': 450,\n",
       " 'talking': 451,\n",
       " 'kindle': 452,\n",
       " 'aw': 453,\n",
       " 'summer': 454,\n",
       " 'laptop': 455,\n",
       " 'brown': 456,\n",
       " 'working': 457,\n",
       " 'told': 458,\n",
       " 'guide': 459,\n",
       " \"you'll\": 460,\n",
       " '7': 461,\n",
       " '100': 462,\n",
       " 'hear': 463,\n",
       " 'part': 464,\n",
       " 'lost': 465,\n",
       " 'babe': 466,\n",
       " 'guy': 467,\n",
       " 'share': 468,\n",
       " 'job': 469,\n",
       " 'anyone': 470,\n",
       " 'ask': 471,\n",
       " 'l': 472,\n",
       " 'bit': 473,\n",
       " 'money': 474,\n",
       " 'whole': 475,\n",
       " 'luck': 476,\n",
       " 'liam': 477,\n",
       " 'both': 478,\n",
       " 'together': 479,\n",
       " '_': 480,\n",
       " 'waiting': 481,\n",
       " 'favorite': 482,\n",
       " \"there's\": 483,\n",
       " 'till': 484,\n",
       " \"we're\": 485,\n",
       " 'thinking': 486,\n",
       " 'fine': 487,\n",
       " 'used': 488,\n",
       " 'enough': 489,\n",
       " 'story': 490,\n",
       " 'welcome': 491,\n",
       " ']': 492,\n",
       " 'party': 493,\n",
       " 'until': 494,\n",
       " 'few': 495,\n",
       " 'lucky': 496,\n",
       " 'fan': 497,\n",
       " 'hours': 498,\n",
       " 'each': 499,\n",
       " 'movie': 500,\n",
       " 'bitch': 501,\n",
       " 'own': 502,\n",
       " 'full': 503,\n",
       " '=': 504,\n",
       " 'seeing': 505,\n",
       " 'enjoy': 506,\n",
       " 'boyfriend': 507,\n",
       " 'wow': 508,\n",
       " 'course': 509,\n",
       " 'win': 510,\n",
       " 'dream': 511,\n",
       " \"isn't\": 512,\n",
       " 'cold': 513,\n",
       " 'later': 514,\n",
       " 'bring': 515,\n",
       " 'late': 516,\n",
       " 'stuff': 517,\n",
       " 'room': 518,\n",
       " 'buy': 519,\n",
       " 'super': 520,\n",
       " 'hp': 521,\n",
       " 'brother': 522,\n",
       " \"let's\": 523,\n",
       " 'wants': 524,\n",
       " 'team': 525,\n",
       " 'yesterday': 526,\n",
       " '9': 527,\n",
       " 'found': 528,\n",
       " 'ugh': 529,\n",
       " 'ha': 530,\n",
       " 'mad': 531,\n",
       " \"they're\": 532,\n",
       " '%': 533,\n",
       " 'replacement': 534,\n",
       " 'came': 535,\n",
       " 'followed': 536,\n",
       " 'change': 537,\n",
       " 'p': 538,\n",
       " 'sexy': 539,\n",
       " 'once': 540,\n",
       " 'hehe': 541,\n",
       " 'far': 542,\n",
       " '(8': 543,\n",
       " 'saying': 544,\n",
       " 'justin': 545,\n",
       " 'special': 546,\n",
       " 'send': 547,\n",
       " 'which': 548,\n",
       " 'soo': 549,\n",
       " 'lovely': 550,\n",
       " 'sucks': 551,\n",
       " 'size': 552,\n",
       " 'bout': 553,\n",
       " 'hell': 554,\n",
       " 'rain': 555,\n",
       " 'alone': 556,\n",
       " 'moment': 557,\n",
       " 'least': 558,\n",
       " 'fucking': 559,\n",
       " 'hit': 560,\n",
       " 'probably': 561,\n",
       " 'body': 562,\n",
       " 'weather': 563,\n",
       " 'crazy': 564,\n",
       " 'hurt': 565,\n",
       " 'else': 566,\n",
       " 'goes': 567,\n",
       " 'forever': 568,\n",
       " 'almost': 569,\n",
       " 'ipod': 570,\n",
       " 'crying': 571,\n",
       " 'notice': 572,\n",
       " 'english': 573,\n",
       " '20': 574,\n",
       " 'single': 575,\n",
       " 'date': 576,\n",
       " 'power': 577,\n",
       " 'place': 578,\n",
       " 'proud': 579,\n",
       " 'green': 580,\n",
       " 'saturday': 581,\n",
       " 'voice': 582,\n",
       " 'dad': 583,\n",
       " 'season': 584,\n",
       " 'camera': 585,\n",
       " 'hello': 586,\n",
       " 'seriously': 587,\n",
       " 'f': 588,\n",
       " 'digital': 589,\n",
       " 'missing': 590,\n",
       " 'gets': 591,\n",
       " 'health': 592,\n",
       " 'eyes': 593,\n",
       " 'playing': 594,\n",
       " 'comes': 595,\n",
       " 'sister': 596,\n",
       " 'yea': 597,\n",
       " 'oz': 598,\n",
       " 'boo': 599,\n",
       " 'shoutout': 600,\n",
       " 'half': 601,\n",
       " 'stupid': 602,\n",
       " \"wasn't\": 603,\n",
       " 'cable': 604,\n",
       " 'light': 605,\n",
       " 'heard': 606,\n",
       " 'called': 607,\n",
       " 'ima': 608,\n",
       " 'didnt': 609,\n",
       " 'retweet': 610,\n",
       " 'small': 611,\n",
       " 'forget': 612,\n",
       " 'lil': 613,\n",
       " 'cuz': 614,\n",
       " 'idk': 615,\n",
       " 'album': 616,\n",
       " 'pic': 617,\n",
       " 'niall': 618,\n",
       " 'number': 619,\n",
       " 'yay': 620,\n",
       " 'dear': 621,\n",
       " 'nooo': 622,\n",
       " 'ah': 623,\n",
       " 'beauty': 624,\n",
       " 'wake': 625,\n",
       " 'sounds': 626,\n",
       " 'ram': 627,\n",
       " 'poor': 628,\n",
       " 'hopefully': 629,\n",
       " 'na': 630,\n",
       " 'hurts': 631,\n",
       " 'reply': 632,\n",
       " 'kids': 633,\n",
       " 'weeks': 634,\n",
       " 'harry': 635,\n",
       " 'needs': 636,\n",
       " 'dog': 637,\n",
       " 'photo': 638,\n",
       " 'american': 639,\n",
       " 'able': 640,\n",
       " 'happen': 641,\n",
       " 'bored': 642,\n",
       " 'dm': 643,\n",
       " 'says': 644,\n",
       " 'ago': 645,\n",
       " 'classic': 646,\n",
       " 'drive': 647,\n",
       " 'goodnight': 648,\n",
       " 'y': 649,\n",
       " 'tickets': 650,\n",
       " 'second': 651,\n",
       " 'easy': 652,\n",
       " 'dance': 653,\n",
       " 'hour': 654,\n",
       " 'dark': 655,\n",
       " 'tour': 656,\n",
       " 'screen': 657,\n",
       " 'worst': 658,\n",
       " 'test': 659,\n",
       " 'run': 660,\n",
       " 'rest': 661,\n",
       " 'either': 662,\n",
       " 'sometimes': 663,\n",
       " 'e': 664,\n",
       " 'forward': 665,\n",
       " 'tv': 666,\n",
       " 'history': 667,\n",
       " 'taking': 668,\n",
       " 'color': 669,\n",
       " 'concert': 670,\n",
       " 'yo': 671,\n",
       " 'laugh': 672,\n",
       " '15': 673,\n",
       " '@': 674,\n",
       " \"couldn't\": 675,\n",
       " 'woke': 676,\n",
       " 'took': 677,\n",
       " 'loves': 678,\n",
       " 'skin': 679,\n",
       " 'ahhh': 680,\n",
       " 'wear': 681,\n",
       " '2012': 682,\n",
       " '16': 683,\n",
       " '18': 684,\n",
       " 'silver': 685,\n",
       " 'means': 686,\n",
       " 'gold': 687,\n",
       " 'lunch': 688,\n",
       " 'product': 689,\n",
       " 'walk': 690,\n",
       " 'forgot': 691,\n",
       " 'toy': 692,\n",
       " 'bro': 693,\n",
       " 'pain': 694,\n",
       " 'prom': 695,\n",
       " 'side': 696,\n",
       " 'jealous': 697,\n",
       " 'wit': 698,\n",
       " 'collection': 699,\n",
       " 'btw': 700,\n",
       " 'th': 701,\n",
       " 'short': 702,\n",
       " 'kind': 703,\n",
       " 'cover': 704,\n",
       " 'kitchen': 705,\n",
       " 'count': 706,\n",
       " 'notebook': 707,\n",
       " \"you've\": 708,\n",
       " 'a-tech': 709,\n",
       " 'reading': 710,\n",
       " 'reason': 711,\n",
       " 'chance': 712,\n",
       " 'loved': 713,\n",
       " 'worry': 714,\n",
       " 'box': 715,\n",
       " 'study': 716,\n",
       " 'idea': 717,\n",
       " \"ain't\": 718,\n",
       " 'wont': 719,\n",
       " 'steel': 720,\n",
       " 'yourself': 721,\n",
       " 'mood': 722,\n",
       " 'touch': 723,\n",
       " 'hahah': 724,\n",
       " 'art': 725,\n",
       " 'sports': 726,\n",
       " 'bag': 727,\n",
       " 'close': 728,\n",
       " 'yours': 729,\n",
       " \"we'll\": 730,\n",
       " 'hand': 731,\n",
       " 'word': 732,\n",
       " 'three': 733,\n",
       " 'business': 734,\n",
       " 'young': 735,\n",
       " 'fall': 736,\n",
       " 'listen': 737,\n",
       " '30': 738,\n",
       " 'city': 739,\n",
       " 'dress': 740,\n",
       " 'break': 741,\n",
       " 'kinda': 742,\n",
       " 'fast': 743,\n",
       " 'ones': 744,\n",
       " 'dinner': 745,\n",
       " 'happened': 746,\n",
       " 'v': 747,\n",
       " 'h': 748,\n",
       " 'open': 749,\n",
       " 'k': 750,\n",
       " 'paper': 751,\n",
       " 'la': 752,\n",
       " 'water': 753,\n",
       " 'support': 754,\n",
       " '24': 755,\n",
       " 'listening': 756,\n",
       " 'card': 757,\n",
       " 'post': 758,\n",
       " 'sex': 759,\n",
       " 'feet': 760,\n",
       " 'leaving': 761,\n",
       " 'style': 762,\n",
       " 'uk': 763,\n",
       " 'turn': 764,\n",
       " 'design': 765,\n",
       " 'started': 766,\n",
       " 'met': 767,\n",
       " 'busy': 768,\n",
       " 'direction': 769,\n",
       " 'plus': 770,\n",
       " '50': 771,\n",
       " 'ddr': 772,\n",
       " 'whats': 773,\n",
       " 'sound': 774,\n",
       " 'die': 775,\n",
       " 'facebook': 776,\n",
       " 'problem': 777,\n",
       " 'feels': 778,\n",
       " 'aint': 779,\n",
       " 'knew': 780,\n",
       " 'scared': 781,\n",
       " 'electronics': 782,\n",
       " 'everyday': 783,\n",
       " 'college': 784,\n",
       " 'words': 785,\n",
       " 'mum': 786,\n",
       " 'thankyou': 787,\n",
       " 'understand': 788,\n",
       " 'finish': 789,\n",
       " 'month': 790,\n",
       " 'ma': 791,\n",
       " 'apple': 792,\n",
       " 'pink': 793,\n",
       " 'move': 794,\n",
       " 'manufactured': 795,\n",
       " '#oomf': 796,\n",
       " 'alright': 797,\n",
       " 'games': 798,\n",
       " 'definitely': 799,\n",
       " 'leather': 800,\n",
       " 'sunday': 801,\n",
       " 'london': 802,\n",
       " 'dude': 803,\n",
       " '11': 804,\n",
       " 'songs': 805,\n",
       " \"wouldn't\": 806,\n",
       " 'point': 807,\n",
       " 'quality': 808,\n",
       " 'account': 809,\n",
       " 'wall': 810,\n",
       " 'upgrade': 811,\n",
       " 'outside': 812,\n",
       " 'totally': 813,\n",
       " 'release': 814,\n",
       " 'months': 815,\n",
       " 'anyway': 816,\n",
       " 'pro': 817,\n",
       " 'running': 818,\n",
       " 'lots': 819,\n",
       " 'tried': 820,\n",
       " 'g': 821,\n",
       " 'eating': 822,\n",
       " 'lmfao': 823,\n",
       " 'rock': 824,\n",
       " 'yu': 825,\n",
       " 'large': 826,\n",
       " 'cut': 827,\n",
       " 'asleep': 828,\n",
       " 'kill': 829,\n",
       " 'tweeting': 830,\n",
       " 'dead': 831,\n",
       " 'lets': 832,\n",
       " 'past': 833,\n",
       " 'official': 834,\n",
       " '#ff': 835,\n",
       " 'girlfriend': 836,\n",
       " 'volume': 837,\n",
       " 'bet': 838,\n",
       " \"y'all\": 839,\n",
       " 'shout': 840,\n",
       " 'knows': 841,\n",
       " 'sun': 842,\n",
       " 'nobody': 843,\n",
       " 'online': 844,\n",
       " 'smh': 845,\n",
       " 'different': 846,\n",
       " 'drink': 847,\n",
       " 'system': 848,\n",
       " 'gave': 849,\n",
       " 'shower': 850,\n",
       " 'exam': 851,\n",
       " 'compatible': 852,\n",
       " 'pictures': 853,\n",
       " '1gb': 854,\n",
       " 'parents': 855,\n",
       " 'hahahaha': 856,\n",
       " 'round': 857,\n",
       " 'double': 858,\n",
       " 'chocolate': 859,\n",
       " 'books': 860,\n",
       " 'blog': 861,\n",
       " 'cat': 862,\n",
       " \"women's\": 863,\n",
       " 'learn': 864,\n",
       " 'plan': 865,\n",
       " 'minutes': 866,\n",
       " 'coffee': 867,\n",
       " 'usb': 868,\n",
       " 'kiss': 869,\n",
       " 'louis': 870,\n",
       " 'ahh': 871,\n",
       " 'bus': 872,\n",
       " 'kid': 873,\n",
       " 'em': 874,\n",
       " 'weird': 875,\n",
       " 'matter': 876,\n",
       " 'answer': 877,\n",
       " 'air': 878,\n",
       " 'twitcam': 879,\n",
       " 'band': 880,\n",
       " 'hungry': 881,\n",
       " 'hug': 882,\n",
       " 'iphone': 883,\n",
       " 'everybody': 884,\n",
       " 'fat': 885,\n",
       " \"who's\": 886,\n",
       " 'da': 887,\n",
       " 'april': 888,\n",
       " 'office': 889,\n",
       " '25': 890,\n",
       " 'instead': 891,\n",
       " 'trip': 892,\n",
       " 'zayn': 893,\n",
       " 'pair': 894,\n",
       " 'asked': 895,\n",
       " 'ball': 896,\n",
       " 'somebody': 897,\n",
       " 'clear': 898,\n",
       " 'monday': 899,\n",
       " 'personal': 900,\n",
       " 'pls': 901,\n",
       " 'nd': 902,\n",
       " 'loool': 903,\n",
       " 'tea': 904,\n",
       " 'version': 905,\n",
       " \":')\": 906,\n",
       " 'pick': 907,\n",
       " 'ice': 908,\n",
       " 'bestfriend': 909,\n",
       " 'hun': 910,\n",
       " 'died': 911,\n",
       " 'cell': 912,\n",
       " 'future': 913,\n",
       " 'sing': 914,\n",
       " 'broke': 915,\n",
       " 'market': 916,\n",
       " 'ugly': 917,\n",
       " 'visit': 918,\n",
       " 'starting': 919,\n",
       " 'travel': 920,\n",
       " 'natural': 921,\n",
       " '4/20': 922,\n",
       " 'print': 923,\n",
       " 'save': 924,\n",
       " 'wonder': 925,\n",
       " 'cream': 926,\n",
       " 'sleeping': 927,\n",
       " '1d': 928,\n",
       " 'ive': 929,\n",
       " 'front': 930,\n",
       " 'ohh': 931,\n",
       " 'country': 932,\n",
       " 'original': 933,\n",
       " 'living': 934,\n",
       " 'write': 935,\n",
       " 'lady': 936,\n",
       " 'congrats': 937,\n",
       " 'works': 938,\n",
       " 'xd': 939,\n",
       " 'hold': 940,\n",
       " 'under': 941,\n",
       " '1st': 942,\n",
       " 'deal': 943,\n",
       " 'aha': 944,\n",
       " 'imma': 945,\n",
       " 'page': 946,\n",
       " 'ppl': 947,\n",
       " 'homework': 948,\n",
       " 'dreams': 949,\n",
       " 'star': 950,\n",
       " 'cried': 951,\n",
       " 'worth': 952,\n",
       " 'finished': 953,\n",
       " 'computer': 954,\n",
       " 'radio': 955,\n",
       " 'inside': 956,\n",
       " 'ipad': 957,\n",
       " 'thursday': 958,\n",
       " 'bye': 959,\n",
       " 'catch': 960,\n",
       " 'capacity': 961,\n",
       " 'exactly': 962,\n",
       " 'link': 963,\n",
       " 'stand': 964,\n",
       " 'gym': 965,\n",
       " 'misc': 966,\n",
       " \"aren't\": 967,\n",
       " 'movies': 968,\n",
       " 'during': 969,\n",
       " 'press': 970,\n",
       " '2nd': 971,\n",
       " 'compaq': 972,\n",
       " 'beat': 973,\n",
       " 'woman': 974,\n",
       " 'type': 975,\n",
       " 'sitting': 976,\n",
       " 'couple': 977,\n",
       " 'club': 978,\n",
       " 'practice': 979,\n",
       " 'shall': 980,\n",
       " '13': 981,\n",
       " 'fact': 982,\n",
       " 'adapter': 983,\n",
       " 'beach': 984,\n",
       " 'join': 985,\n",
       " 'french': 986,\n",
       " 'yall': 987,\n",
       " 'seems': 988,\n",
       " 'havent': 989,\n",
       " 'sent': 990,\n",
       " 'men': 991,\n",
       " 'bday': 992,\n",
       " 'less': 993,\n",
       " 'mate': 994,\n",
       " 'smoke': 995,\n",
       " 'yellow': 996,\n",
       " 'library': 997,\n",
       " 'stories': 998,\n",
       " \"men's\": 999,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('vocab_full.pkl', 'rb') as f :\n",
    "    vocab = pickle.load(f)\n",
    "xs = np.load(file_storing_ts)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3.Construct features for training tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = open(file_storing_pos_ts_tweets, 'r').readlines() \n",
    "neg_tweets = open(file_storing_neg_ts_tweets, 'r').readlines()\n",
    "\n",
    "\n",
    "#Construct features for positive tweets\n",
    "pos_features = []\n",
    "\n",
    "for line in pos_tweets:\n",
    "    sum_w = np.zeros(nb_dim)\n",
    "    count = 0\n",
    "    for word in line.split():\n",
    "        local_w = vocab.get(word, -1)\n",
    "        if local_w != -1:\n",
    "            count += 1\n",
    "            sum_w += xs[local_w]\n",
    "     \n",
    "    # If no match between the vocab and the tweet, we set the feature vector to zeros (zero best value ?)\n",
    "    if(count == 0):\n",
    "        count = 1\n",
    "    pos_features.append(sum_w/count)\n",
    "pos_features = np.array(pos_features)    \n",
    "    \n",
    "#Construct features for negative tweets\n",
    "neg_features = []\n",
    "\n",
    "for line in neg_tweets:\n",
    "    sum_w = np.zeros(nb_dim)\n",
    "    count = 0\n",
    "    for word in line.split():\n",
    "        local_w = vocab.get(word, -1)\n",
    "        if local_w != -1:\n",
    "            count += 1\n",
    "            sum_w += xs[local_w]\n",
    "     \n",
    "    # If no match between the vocab and the tweet, we set the feature vector to zeros (zero best value ?)\n",
    "    if(count == 0):\n",
    "        count = 1\n",
    "    neg_features.append(sum_w/count)\n",
    "    \n",
    "neg_features = np.array(neg_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Train the linear classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(n_iter=400, warm_start=True);\n",
    "X = np.concatenate((pos_features, neg_features))\n",
    "scaler = preprocessing.StandardScaler()\n",
    "Y = np.concatenate((np.ones(len(pos_features)), np.full(len(neg_features), -1)))\n",
    "X = scaler.fit_transform(X, Y)\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  53.55488 %\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy : \", (1 - (np.sum(np.abs(Y-prediction))/(2*len(Y)))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
